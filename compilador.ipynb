{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a758a5e",
   "metadata": {},
   "source": [
    "\n",
    "COMPILADOR - ANÃLISE LÃ‰XICA E SINTÃTICA LL(1) E SLR(1)\n",
    "ImplementaÃ§Ã£o de um compilador para uma linguagem de programaÃ§Ã£o simplificada\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "941cd968",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from enum import Enum\n",
    "from typing import List, Dict, Set, Tuple, Optional\n",
    "from dataclasses import dataclass\n",
    "from collections import defaultdict, deque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bb734bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANALISADOR LÃ‰XICO (SCANNER)\n",
    "\n",
    "class TokenType(Enum):\n",
    "    \"\"\"Classes de Lexemas (Tokens)\"\"\"\n",
    "    # Palavras-chave\n",
    "    INT = 'INT'\n",
    "    FLOAT = 'FLOAT'\n",
    "    DOUBLE = 'DOUBLE'\n",
    "    MAIN = 'MAIN'\n",
    "    IF = 'IF'\n",
    "    ELSE = 'ELSE'\n",
    "    WHILE = 'WHILE'\n",
    "    FOR = 'FOR'\n",
    "    RETURN = 'RETURN'\n",
    "    \n",
    "    # Identificadores e literais\n",
    "    IDENTIFIER = 'IDENTIFIER'\n",
    "    NUMBER_INT = 'NUMBER_INT'\n",
    "    NUMBER_FLOAT = 'NUMBER_FLOAT'\n",
    "    \n",
    "    # Operadores aritmÃ©ticos\n",
    "    PLUS = 'PLUS'\n",
    "    MINUS = 'MINUS'\n",
    "    MULTIPLY = 'MULTIPLY'\n",
    "    DIVIDE = 'DIVIDE'\n",
    "    \n",
    "    # Operadores relacionais\n",
    "    EQUAL = 'EQUAL'\n",
    "    NOT_EQUAL = 'NOT_EQUAL'\n",
    "    LESS_THAN = 'LESS_THAN'\n",
    "    GREATER_THAN = 'GREATER_THAN'\n",
    "    LESS_EQUAL = 'LESS_EQUAL'\n",
    "    GREATER_EQUAL = 'GREATER_EQUAL'\n",
    "    \n",
    "    # Operadores lÃ³gicos\n",
    "    AND = 'AND'\n",
    "    OR = 'OR'\n",
    "    NOT = 'NOT'\n",
    "    \n",
    "    # AtribuiÃ§Ã£o\n",
    "    ASSIGN = 'ASSIGN'\n",
    "    \n",
    "    # Delimitadores\n",
    "    LPAREN = 'LPAREN'\n",
    "    RPAREN = 'RPAREN'\n",
    "    LBRACE = 'LBRACE'\n",
    "    RBRACE = 'RBRACE'\n",
    "    SEMICOLON = 'SEMICOLON'\n",
    "    COMMA = 'COMMA'\n",
    "    \n",
    "    # Especiais\n",
    "    EOF = 'EOF'\n",
    "    EPSILON = 'EPSILON'\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Token:\n",
    "    \"\"\"Estrutura de um Token\"\"\"\n",
    "    type: TokenType\n",
    "    value: str\n",
    "    line: int\n",
    "    column: int\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"Token({self.type.name}, '{self.value}', L{self.line}:C{self.column})\"\n",
    "\n",
    "\n",
    "class LexicalAnalyzer:\n",
    "    \"\"\"Analisador LÃ©xico (Scanner) - ImplementaÃ§Ã£o Pura\"\"\"\n",
    "    \n",
    "    # ExpressÃµes Regulares para cada tipo de token\n",
    "    TOKEN_PATTERNS = [\n",
    "        # Palavras-chave (devem vir antes de IDENTIFIER)\n",
    "        (r'\\bint\\b', TokenType.INT),\n",
    "        (r'\\bfloat\\b', TokenType.FLOAT),\n",
    "        (r'\\bdouble\\b', TokenType.DOUBLE),\n",
    "        (r'\\bmain\\b', TokenType.MAIN),\n",
    "        (r'\\bif\\b', TokenType.IF),\n",
    "        (r'\\belse\\b', TokenType.ELSE),\n",
    "        (r'\\bwhile\\b', TokenType.WHILE),\n",
    "        (r'\\bfor\\b', TokenType.FOR),\n",
    "        (r'\\breturn\\b', TokenType.RETURN),\n",
    "        \n",
    "        # Identificadores: [a-zA-Z_][a-zA-Z0-9_]*\n",
    "        (r'[a-zA-Z_][a-zA-Z0-9_]*', TokenType.IDENTIFIER),\n",
    "        \n",
    "        # NÃºmeros: float tem ponto decimal, int nÃ£o tem\n",
    "        (r'\\d+\\.\\d+', TokenType.NUMBER_FLOAT),\n",
    "        (r'\\d+', TokenType.NUMBER_INT),\n",
    "        \n",
    "        # Operadores relacionais (devem vir antes dos simples)\n",
    "        (r'==', TokenType.EQUAL),\n",
    "        (r'!=', TokenType.NOT_EQUAL),\n",
    "        (r'<=', TokenType.LESS_EQUAL),\n",
    "        (r'>=', TokenType.GREATER_EQUAL),\n",
    "        (r'<', TokenType.LESS_THAN),\n",
    "        (r'>', TokenType.GREATER_THAN),\n",
    "        \n",
    "        # Operadores lÃ³gicos\n",
    "        (r'&&', TokenType.AND),\n",
    "        (r'\\|\\|', TokenType.OR),\n",
    "        (r'!', TokenType.NOT),\n",
    "        \n",
    "        # Operadores aritmÃ©ticos\n",
    "        (r'\\+', TokenType.PLUS),\n",
    "        (r'-', TokenType.MINUS),\n",
    "        (r'\\*', TokenType.MULTIPLY),\n",
    "        (r'/', TokenType.DIVIDE),\n",
    "        \n",
    "        # AtribuiÃ§Ã£o\n",
    "        (r'=', TokenType.ASSIGN),\n",
    "        \n",
    "        # Delimitadores\n",
    "        (r'\\(', TokenType.LPAREN),\n",
    "        (r'\\)', TokenType.RPAREN),\n",
    "        (r'\\{', TokenType.LBRACE),\n",
    "        (r'\\}', TokenType.RBRACE),\n",
    "        (r';', TokenType.SEMICOLON),\n",
    "        (r',', TokenType.COMMA),\n",
    "        \n",
    "        # Whitespace (ignorado)\n",
    "        (r'[ \\t]+', None),\n",
    "        (r'\\n', None),\n",
    "    ]\n",
    "    \n",
    "    def __init__(self, source_code: str):\n",
    "        self.source_code = source_code\n",
    "        self.tokens: List[Token] = []\n",
    "        self.current_line = 1\n",
    "        self.current_column = 1\n",
    "    \n",
    "    def tokenize(self) -> List[Token]:\n",
    "        \"\"\"Realiza a anÃ¡lise lÃ©xica completa\"\"\"\n",
    "        position = 0\n",
    "        \n",
    "        while position < len(self.source_code):\n",
    "            match_found = False\n",
    "            \n",
    "            for pattern, token_type in self.TOKEN_PATTERNS:\n",
    "                regex = re.compile(pattern)\n",
    "                match = regex.match(self.source_code, position)\n",
    "                \n",
    "                if match:\n",
    "                    lexeme = match.group(0)\n",
    "                    \n",
    "                    if token_type is not None:  # NÃ£o Ã© whitespace\n",
    "                        token = Token(\n",
    "                            type=token_type,\n",
    "                            value=lexeme,\n",
    "                            line=self.current_line,\n",
    "                            column=self.current_column\n",
    "                        )\n",
    "                        self.tokens.append(token)\n",
    "                    \n",
    "                    # Atualiza posiÃ§Ã£o\n",
    "                    position = match.end()\n",
    "                    \n",
    "                    # Atualiza linha e coluna\n",
    "                    if lexeme == '\\n':\n",
    "                        self.current_line += 1\n",
    "                        self.current_column = 1\n",
    "                    else:\n",
    "                        self.current_column += len(lexeme)\n",
    "                    \n",
    "                    match_found = True\n",
    "                    break\n",
    "            \n",
    "            if not match_found:\n",
    "                char = self.source_code[position]\n",
    "                raise SyntaxError(\n",
    "                    f\"Caractere invÃ¡lido '{char}' na linha {self.current_line}, \"\n",
    "                    f\"coluna {self.current_column}\"\n",
    "                )\n",
    "        \n",
    "        # Adiciona token EOF\n",
    "        self.tokens.append(Token(TokenType.EOF, '', self.current_line, self.current_column))\n",
    "        return self.tokens\n",
    "    \n",
    "    def get_token_chain(self) -> str:\n",
    "        \"\"\"Retorna a cadeia de tokens formatada\"\"\"\n",
    "        return ' '.join([f\"{token.type.name}\" for token in self.tokens if token.type != TokenType.EOF])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b780e16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRAMÃTICA E TRANSFORMAÃ‡Ã•ES PARA LL(1)\n",
    "\n",
    "class Grammar:\n",
    "    \"\"\"RepresentaÃ§Ã£o da GramÃ¡tica Livre de Contexto\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.productions: Dict[str, List[List[str]]] = {}\n",
    "        self.start_symbol: str = 'Program'\n",
    "        self.terminals: Set[str] = set()\n",
    "        self.non_terminals: Set[str] = set()\n",
    "    \n",
    "    def add_production(self, left: str, right: List[str]):\n",
    "        \"\"\"Adiciona uma produÃ§Ã£o Ã  gramÃ¡tica\"\"\"\n",
    "        if left not in self.productions:\n",
    "            self.productions[left] = []\n",
    "        self.productions[left].append(right)\n",
    "        self.non_terminals.add(left)\n",
    "        \n",
    "        for symbol in right:\n",
    "            if symbol == 'EPSILON':\n",
    "                continue\n",
    "            if '_' in symbol or (symbol.isupper() and len(symbol) > 1 and not any(c.islower() for c in symbol)):\n",
    "                self.terminals.add(symbol)\n",
    "            elif symbol[0].isupper() and any(c.islower() for c in symbol):\n",
    "                pass\n",
    "    \n",
    "    def __repr__(self):\n",
    "        result = []\n",
    "        for left, rights in self.productions.items():\n",
    "            for right in rights:\n",
    "                result.append(f\"{left} -> {' '.join(right)}\")\n",
    "        return '\\n'.join(result)\n",
    "\n",
    "\n",
    "def create_ll1_grammar() -> Grammar:\n",
    "    \"\"\"Cria a gramÃ¡tica LL(1) para a linguagem\"\"\"\n",
    "    \n",
    "    g = Grammar()\n",
    "    \n",
    "    # Program\n",
    "    g.add_production('Program', ['MAIN', 'LPAREN', 'RPAREN', 'LBRACE', 'StmtList', 'RBRACE'])\n",
    "    \n",
    "    # StmtList\n",
    "    g.add_production('StmtList', ['Stmt', 'StmtList'])\n",
    "    g.add_production('StmtList', ['EPSILON'])\n",
    "    \n",
    "    # Stmt\n",
    "    g.add_production('Stmt', ['DeclStmt'])\n",
    "    g.add_production('Stmt', ['AssignStmt'])\n",
    "    g.add_production('Stmt', ['IfStmt'])\n",
    "    g.add_production('Stmt', ['WhileStmt'])\n",
    "    g.add_production('Stmt', ['ForStmt'])\n",
    "    \n",
    "    # DeclStmt\n",
    "    g.add_production('DeclStmt', ['Type', 'IDENTIFIER', 'SEMICOLON'])\n",
    "    \n",
    "    # Type\n",
    "    g.add_production('Type', ['INT'])\n",
    "    g.add_production('Type', ['FLOAT'])\n",
    "    g.add_production('Type', ['DOUBLE'])\n",
    "    \n",
    "    # AssignStmt\n",
    "    g.add_production('AssignStmt', ['IDENTIFIER', 'ASSIGN', 'Expr', 'SEMICOLON'])\n",
    "    \n",
    "    # IfStmt\n",
    "    g.add_production('IfStmt', ['IF', 'LPAREN', 'Condition', 'RPAREN', 'LBRACE', 'StmtList', 'RBRACE', 'ElsePart'])\n",
    "    \n",
    "    # ElsePart\n",
    "    g.add_production('ElsePart', ['ELSE', 'LBRACE', 'StmtList', 'RBRACE'])\n",
    "    g.add_production('ElsePart', ['EPSILON'])\n",
    "    \n",
    "    # WhileStmt\n",
    "    g.add_production('WhileStmt', ['WHILE', 'LPAREN', 'Condition', 'RPAREN', 'LBRACE', 'StmtList', 'RBRACE'])\n",
    "    \n",
    "    # ForStmt\n",
    "    g.add_production('ForStmt', ['FOR', 'LPAREN', 'AssignStmt', 'Condition', 'SEMICOLON', 'IDENTIFIER', 'ASSIGN', 'Expr', 'RPAREN', 'LBRACE', 'StmtList', 'RBRACE'])\n",
    "    \n",
    "    # Condition\n",
    "    g.add_production('Condition', ['Expr', 'RelOp', 'Expr'])\n",
    "    \n",
    "    # Expr\n",
    "    g.add_production('Expr', ['Term', 'ExprTail'])\n",
    "    \n",
    "    # ExprTail\n",
    "    g.add_production('ExprTail', ['PLUS', 'Term', 'ExprTail'])\n",
    "    g.add_production('ExprTail', ['MINUS', 'Term', 'ExprTail'])\n",
    "    g.add_production('ExprTail', ['EPSILON'])\n",
    "    \n",
    "    # Term\n",
    "    g.add_production('Term', ['Factor', 'TermTail'])\n",
    "    \n",
    "    # TermTail\n",
    "    g.add_production('TermTail', ['MULTIPLY', 'Factor', 'TermTail'])\n",
    "    g.add_production('TermTail', ['DIVIDE', 'Factor', 'TermTail'])\n",
    "    g.add_production('TermTail', ['EPSILON'])\n",
    "    \n",
    "    # Factor\n",
    "    g.add_production('Factor', ['IDENTIFIER'])\n",
    "    g.add_production('Factor', ['NUMBER_INT'])\n",
    "    g.add_production('Factor', ['NUMBER_FLOAT'])\n",
    "    g.add_production('Factor', ['LPAREN', 'Expr', 'RPAREN'])\n",
    "    \n",
    "    # RelOp\n",
    "    g.add_production('RelOp', ['EQUAL'])\n",
    "    g.add_production('RelOp', ['NOT_EQUAL'])\n",
    "    g.add_production('RelOp', ['LESS_THAN'])\n",
    "    g.add_production('RelOp', ['GREATER_THAN'])\n",
    "    g.add_production('RelOp', ['LESS_EQUAL'])\n",
    "    g.add_production('RelOp', ['GREATER_EQUAL'])\n",
    "    \n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2762c5f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CÃLCULO DE FIRST E FOLLOW\n",
    "\n",
    "class FirstFollowCalculator:\n",
    "    \"\"\"Calcula os conjuntos FIRST e FOLLOW da gramÃ¡tica\"\"\"\n",
    "    \n",
    "    def __init__(self, grammar: Grammar):\n",
    "        self.grammar = grammar\n",
    "        self.first: Dict[str, Set[str]] = {}\n",
    "        self.follow: Dict[str, Set[str]] = {}\n",
    "    \n",
    "    def calculate_first(self) -> Dict[str, Set[str]]:\n",
    "        \"\"\"Calcula o conjunto FIRST para cada sÃ­mbolo\"\"\"\n",
    "        for terminal in self.grammar.terminals:\n",
    "            self.first[terminal] = {terminal}\n",
    "        \n",
    "        for non_terminal in self.grammar.non_terminals:\n",
    "            self.first[non_terminal] = set()\n",
    "        \n",
    "        self.first['EPSILON'] = {'EPSILON'}\n",
    "        \n",
    "        changed = True\n",
    "        while changed:\n",
    "            changed = False\n",
    "            \n",
    "            for left, productions in self.grammar.productions.items():\n",
    "                for production in productions:\n",
    "                    old_size = len(self.first[left])\n",
    "                    \n",
    "                    for symbol in production:\n",
    "                        first_symbol = self.first.get(symbol, set())\n",
    "                        self.first[left] |= (first_symbol - {'EPSILON'})\n",
    "                        \n",
    "                        if 'EPSILON' not in first_symbol:\n",
    "                            break\n",
    "                    else:\n",
    "                        self.first[left].add('EPSILON')\n",
    "                    \n",
    "                    if len(self.first[left]) > old_size:\n",
    "                        changed = True\n",
    "        \n",
    "        return self.first\n",
    "    \n",
    "    def calculate_follow(self) -> Dict[str, Set[str]]:\n",
    "        \"\"\"Calcula o conjunto FOLLOW para cada nÃ£o-terminal\"\"\"\n",
    "        for non_terminal in self.grammar.non_terminals:\n",
    "            self.follow[non_terminal] = set()\n",
    "        \n",
    "        self.follow[self.grammar.start_symbol].add('$')\n",
    "        \n",
    "        changed = True\n",
    "        while changed:\n",
    "            changed = False\n",
    "            \n",
    "            for left, productions in self.grammar.productions.items():\n",
    "                for production in productions:\n",
    "                    for i, symbol in enumerate(production):\n",
    "                        if symbol not in self.grammar.non_terminals:\n",
    "                            continue\n",
    "                        \n",
    "                        old_size = len(self.follow[symbol])\n",
    "                        \n",
    "                        rest = production[i+1:]\n",
    "                        if rest:\n",
    "                            for next_symbol in rest:\n",
    "                                first_next = self.first.get(next_symbol, set())\n",
    "                                self.follow[symbol] |= (first_next - {'EPSILON'})\n",
    "                                \n",
    "                                if 'EPSILON' not in first_next:\n",
    "                                    break\n",
    "                            else:\n",
    "                                self.follow[symbol] |= self.follow[left]\n",
    "                        else:\n",
    "                            self.follow[symbol] |= self.follow[left]\n",
    "                        \n",
    "                        if len(self.follow[symbol]) > old_size:\n",
    "                            changed = True\n",
    "        \n",
    "        return self.follow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e539cce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TABELA DE ANÃLISE SINTÃTICA LL(1)\n",
    "\n",
    "class LL1Parser:\n",
    "    \"\"\"Analisador SintÃ¡tico LL(1)\"\"\"\n",
    "    \n",
    "    def __init__(self, grammar: Grammar):\n",
    "        self.grammar = grammar\n",
    "        self.calculator = FirstFollowCalculator(grammar)\n",
    "        self.first = self.calculator.calculate_first()\n",
    "        self.follow = self.calculator.calculate_follow()\n",
    "        self.parsing_table: Dict[Tuple[str, str], List[str]] = {}\n",
    "        self.build_parsing_table()\n",
    "    \n",
    "    def build_parsing_table(self):\n",
    "        \"\"\"ConstrÃ³i a tabela de anÃ¡lise sintÃ¡tica LL(1)\"\"\"\n",
    "        for left, productions in self.grammar.productions.items():\n",
    "            for production in productions:\n",
    "                first_prod = set()\n",
    "                for symbol in production:\n",
    "                    first_symbol = self.first.get(symbol, set())\n",
    "                    first_prod |= (first_symbol - {'EPSILON'})\n",
    "                    if 'EPSILON' not in first_symbol:\n",
    "                        break\n",
    "                else:\n",
    "                    first_prod.add('EPSILON')\n",
    "                \n",
    "                for terminal in first_prod:\n",
    "                    if terminal != 'EPSILON':\n",
    "                        if (left, terminal) in self.parsing_table:\n",
    "                            print(f\"CONFLITO LL(1) em [{left}, {terminal}]\")\n",
    "                        self.parsing_table[(left, terminal)] = production\n",
    "                \n",
    "                if 'EPSILON' in first_prod:\n",
    "                    for terminal in self.follow.get(left, set()):\n",
    "                        if (left, terminal) in self.parsing_table:\n",
    "                            print(f\"CONFLITO LL(1) em [{left}, {terminal}]\")\n",
    "                        self.parsing_table[(left, terminal)] = production\n",
    "    \n",
    "    def parse(self, tokens: List[Token], verbose: bool = True) -> bool:\n",
    "        \"\"\"Realiza a anÃ¡lise sintÃ¡tica usando pilha\"\"\"\n",
    "        stack = ['$', self.grammar.start_symbol]\n",
    "        token_index = 0\n",
    "        \n",
    "        if verbose:\n",
    "            print(\"\\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\")\n",
    "            print(\"â”‚              ANÃLISE SINTÃTICA LL(1) - TRACE                   â”‚\")\n",
    "            print(\"â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\\n\")\n",
    "        \n",
    "        steps = 0\n",
    "        while stack:\n",
    "            top = stack[-1]\n",
    "            current_token = tokens[token_index]\n",
    "            current_symbol = current_token.type.name\n",
    "            \n",
    "            if verbose and steps < 10:\n",
    "                print(f\"Passo {steps+1}: Topo={top}, Token={current_symbol}\")\n",
    "            \n",
    "            if top == '$':\n",
    "                if current_symbol == 'EOF':\n",
    "                    if verbose:\n",
    "                        print(f\"\\nâœ“ AnÃ¡lise concluÃ­da com sucesso!\")\n",
    "                    return True\n",
    "                else:\n",
    "                    if verbose:\n",
    "                        print(f\"\\nâœ— ERRO: esperado EOF, encontrado {current_symbol}\")\n",
    "                    return False\n",
    "            \n",
    "            elif top == current_symbol:\n",
    "                stack.pop()\n",
    "                token_index += 1\n",
    "                steps += 1\n",
    "            \n",
    "            elif top in self.grammar.non_terminals:\n",
    "                if (top, current_symbol) in self.parsing_table:\n",
    "                    production = self.parsing_table[(top, current_symbol)]\n",
    "                    stack.pop()\n",
    "                    if production != ['EPSILON']:\n",
    "                        stack.extend(reversed(production))\n",
    "                    steps += 1\n",
    "                else:\n",
    "                    if verbose:\n",
    "                        print(f\"\\nâœ— ERRO: sem produÃ§Ã£o para [{top}, {current_symbol}]\")\n",
    "                    return False\n",
    "            \n",
    "            else:\n",
    "                if verbose:\n",
    "                    print(f\"\\nâœ— ERRO: esperado {top}, encontrado {current_symbol}\")\n",
    "                return False\n",
    "        \n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "66ca9bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRAMÃTICA E ITENS LR(0) PARA SLR(1)\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class LRItem:\n",
    "    \"\"\"Representa um item LR(0): A -> Î±.Î²\"\"\"\n",
    "    left: str\n",
    "    right: Tuple[str, ...]\n",
    "    dot_position: int\n",
    "    \n",
    "    def __repr__(self):\n",
    "        right_list = list(self.right)\n",
    "        right_list.insert(self.dot_position, '.')\n",
    "        return f\"{self.left} -> {' '.join(right_list)}\"\n",
    "    \n",
    "    def next_symbol(self) -> Optional[str]:\n",
    "        \"\"\"Retorna o sÃ­mbolo apÃ³s o ponto\"\"\"\n",
    "        if self.dot_position < len(self.right):\n",
    "            return self.right[self.dot_position]\n",
    "        return None\n",
    "    \n",
    "    def advance(self) -> 'LRItem':\n",
    "        \"\"\"AvanÃ§a o ponto uma posiÃ§Ã£o\"\"\"\n",
    "        return LRItem(self.left, self.right, self.dot_position + 1)\n",
    "    \n",
    "    def is_complete(self) -> bool:\n",
    "        \"\"\"Verifica se o item estÃ¡ completo (ponto no final)\"\"\"\n",
    "        return self.dot_position >= len(self.right)\n",
    "\n",
    "\n",
    "class SLRParser:\n",
    "    \"\"\"Analisador SintÃ¡tico SLR(1)\"\"\"\n",
    "    \n",
    "    def __init__(self, grammar: Grammar):\n",
    "        self.grammar = self.augment_grammar(grammar)\n",
    "        self.calculator = FirstFollowCalculator(self.grammar)\n",
    "        self.first = self.calculator.calculate_first()\n",
    "        self.follow = self.calculator.calculate_follow()\n",
    "        \n",
    "        self.states: List[Set[LRItem]] = []\n",
    "        self.goto_table: Dict[Tuple[int, str], int] = {}\n",
    "        self.action_table: Dict[Tuple[int, str], Tuple[str, int]] = {}\n",
    "        \n",
    "        self.build_lr0_collection()\n",
    "        self.build_slr_table()\n",
    "    \n",
    "    def augment_grammar(self, grammar: Grammar) -> Grammar:\n",
    "        \"\"\"Aumenta a gramÃ¡tica: S' -> S\"\"\"\n",
    "        aug_grammar = Grammar()\n",
    "        aug_grammar.start_symbol = \"Program'\"\n",
    "        \n",
    "        aug_grammar.add_production(\"Program'\", [grammar.start_symbol])\n",
    "        \n",
    "        for left, productions in grammar.productions.items():\n",
    "            for production in productions:\n",
    "                aug_grammar.add_production(left, production)\n",
    "        \n",
    "        return aug_grammar\n",
    "    \n",
    "    def closure(self, items: Set[LRItem]) -> Set[LRItem]:\n",
    "        \"\"\"Calcula o fechamento de um conjunto de itens - TRATAMENTO ESPECIAL PARA EPSILON\"\"\"\n",
    "        closure_set = set(items)\n",
    "        changed = True\n",
    "        \n",
    "        while changed:\n",
    "            changed = False\n",
    "            new_items = set()\n",
    "            \n",
    "            for item in closure_set:\n",
    "                next_sym = item.next_symbol()\n",
    "                \n",
    "                # Se o prÃ³ximo sÃ­mbolo Ã© um nÃ£o-terminal\n",
    "                if next_sym and next_sym in self.grammar.non_terminals:\n",
    "                    # Adiciona todos os itens para produÃ§Ãµes deste nÃ£o-terminal\n",
    "                    for production in self.grammar.productions.get(next_sym, []):\n",
    "                        new_item = LRItem(next_sym, tuple(production), 0)\n",
    "                        \n",
    "                        # TRATAMENTO ESPECIAL: Se a produÃ§Ã£o Ã© A -> EPSILON\n",
    "                        # TambÃ©m adiciona o item completo A -> EPSILON.\n",
    "                        if production == ['EPSILON']:\n",
    "                            # Item jÃ¡ comeÃ§a completo (ponto apÃ³s EPSILON)\n",
    "                            completed_item = LRItem(next_sym, tuple(production), 1)\n",
    "                            if completed_item not in closure_set and completed_item not in new_items:\n",
    "                                new_items.add(completed_item)\n",
    "                                changed = True\n",
    "                        \n",
    "                        if new_item not in closure_set and new_item not in new_items:\n",
    "                            new_items.add(new_item)\n",
    "                            changed = True\n",
    "            \n",
    "            closure_set |= new_items\n",
    "        \n",
    "        return closure_set\n",
    "    \n",
    "    def goto(self, items: Set[LRItem], symbol: str) -> Set[LRItem]:\n",
    "        \"\"\"Calcula GOTO(I, X) - IGNORA EPSILON\"\"\"\n",
    "        goto_set = set()\n",
    "        \n",
    "        for item in items:\n",
    "            next = item.next_symbol()\n",
    "            # IMPORTANTE: EPSILON nunca Ã© \"consumido\" pelo GOTO\n",
    "            if next == symbol and symbol != 'EPSILON':\n",
    "                goto_set.add(item.advance())\n",
    "        \n",
    "        return self.closure(goto_set)\n",
    "    \n",
    "    def build_lr0_collection(self):\n",
    "        \"\"\"ConstrÃ³i a coleÃ§Ã£o de itens LR(0)\"\"\"\n",
    "        initial_production = self.grammar.productions[self.grammar.start_symbol][0]\n",
    "        initial_item = LRItem(self.grammar.start_symbol, tuple(initial_production), 0)\n",
    "        initial_state = self.closure({initial_item})\n",
    "        \n",
    "        self.states = [initial_state]\n",
    "        unprocessed = [0]\n",
    "        \n",
    "        while unprocessed:\n",
    "            state_idx = unprocessed.pop(0)\n",
    "            current_state = self.states[state_idx]\n",
    "            \n",
    "            # Coleta todos os sÃ­mbolos possÃ­veis (exceto EPSILON)\n",
    "            symbols = set()\n",
    "            for item in current_state:\n",
    "                next_sym = item.next_symbol()\n",
    "                if next_sym and next_sym != 'EPSILON':\n",
    "                    symbols.add(next_sym)\n",
    "            \n",
    "            for symbol in symbols:\n",
    "                goto_state = self.goto(current_state, symbol)\n",
    "                \n",
    "                if not goto_state:\n",
    "                    continue\n",
    "                \n",
    "                try:\n",
    "                    target_idx = self.states.index(goto_state)\n",
    "                except ValueError:\n",
    "                    target_idx = len(self.states)\n",
    "                    self.states.append(goto_state)\n",
    "                    unprocessed.append(target_idx)\n",
    "                \n",
    "                self.goto_table[(state_idx, symbol)] = target_idx\n",
    "    \n",
    "    def build_slr_table(self):\n",
    "        \"\"\"ConstrÃ³i a tabela de parsing SLR(1) - VERSÃƒO FINAL\"\"\"\n",
    "        \n",
    "        # PASSO 1: Adiciona SHIFTS (tÃªm precedÃªncia)\n",
    "        for (state_idx, symbol), target in self.goto_table.items():\n",
    "            if symbol in self.grammar.terminals:\n",
    "                self.action_table[(state_idx, symbol)] = ('shift', target)\n",
    "        \n",
    "        # PASSO 2: Adiciona REDUCES e ACCEPT\n",
    "        for state_idx, state in enumerate(self.states):\n",
    "            for item in state:\n",
    "                \n",
    "                # Item completo (A -> Î±.)\n",
    "                if item.is_complete():\n",
    "                    \n",
    "                    # Accept\n",
    "                    if item.left == self.grammar.start_symbol:\n",
    "                        self.action_table[(state_idx, '$')] = ('accept', 0)\n",
    "                    \n",
    "                    # Reduce\n",
    "                    else:\n",
    "                        prod_idx = self.find_production_index(item.left, item.right)\n",
    "                        follow_set = self.follow.get(item.left, set())\n",
    "                        \n",
    "                        # Adiciona reduce para todos os terminais no FOLLOW\n",
    "                        for terminal in follow_set:\n",
    "                            key = (state_idx, terminal)\n",
    "                            \n",
    "                            # Se jÃ¡ tem shift, NÃƒO sobrescreve (shift tem precedÃªncia)\n",
    "                            if key not in self.action_table:\n",
    "                                self.action_table[key] = ('reduce', prod_idx)\n",
    "    \n",
    "    def find_production_index(self, left: str, right: Tuple[str, ...]) -> int:\n",
    "        \"\"\"Encontra o Ã­ndice de uma produÃ§Ã£o\"\"\"\n",
    "        idx = 0\n",
    "        for l, productions in self.grammar.productions.items():\n",
    "            for prod in productions:\n",
    "                if l == left and tuple(prod) == right:\n",
    "                    return idx\n",
    "                idx += 1\n",
    "        return -1\n",
    "    \n",
    "    def get_production_by_index(self, idx: int) -> Tuple[str, List[str]]:\n",
    "        \"\"\"Retorna uma produÃ§Ã£o pelo Ã­ndice\"\"\"\n",
    "        current = 0\n",
    "        for left, productions in self.grammar.productions.items():\n",
    "            for prod in productions:\n",
    "                if current == idx:\n",
    "                    return (left, prod)\n",
    "                current += 1\n",
    "        return ('', [])\n",
    "    \n",
    "    def parse(self, tokens: List[Token], verbose: bool = True) -> bool:\n",
    "        \"\"\"Realiza a anÃ¡lise sintÃ¡tica SLR(1)\"\"\"\n",
    "        stack = [0]\n",
    "        token_index = 0\n",
    "        \n",
    "        if verbose:\n",
    "            log_output(\"\\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\")\n",
    "            log_output(\"â”‚              ANÃLISE SINTÃTICA SLR(1) - TRACE                  â”‚\")\n",
    "            log_output(\"â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\\n\")\n",
    "            log_output(\"â”‚  Mostrando apenas primeiros 10 passos no console...\")\n",
    "            log_output(\"â”‚  Trace completo salvo no arquivo.\", print_console=False)\n",
    "            log_output(\"â”‚\", print_console=False)\n",
    "        \n",
    "        steps = 0\n",
    "        while True:\n",
    "            state = stack[-1]\n",
    "            current_token = tokens[token_index]\n",
    "            symbol = current_token.type.name if current_token.type != TokenType.EOF else '$'\n",
    "            \n",
    "            # Log completo no arquivo\n",
    "            stack_str = ' '.join(map(str, stack[:5])) + ('...' if len(stack) > 5 else '')\n",
    "            step_detail = f\"â”‚  Passo {steps+1}: Pilha=[{stack_str}], Token={symbol}\"\n",
    "            \n",
    "            if verbose and steps < 10:\n",
    "                log_output(f\"Passo {steps+1}: Estado={state}, Token={symbol}\")\n",
    "            \n",
    "            log_output(step_detail, print_console=False)\n",
    "            \n",
    "            if (state, symbol) not in self.action_table:\n",
    "                if verbose:\n",
    "                    log_output(f\"\\nâœ— ERRO: aÃ§Ã£o indefinida para estado {state}, token {symbol}\")\n",
    "                    log_output(f\"   Pilha: {stack}\")\n",
    "                    \n",
    "                    # Mostra aÃ§Ãµes disponÃ­veis\n",
    "                    available = sorted(set(t for s, t in self.action_table.keys() if s == state))\n",
    "                    log_output(f\"   AÃ§Ãµes disponÃ­veis no estado {state}: {available}\")\n",
    "                    \n",
    "                    # Mostra itens do estado\n",
    "                    log_output(f\"   Itens no estado {state}:\")\n",
    "                    for item in sorted(self.states[state], key=str):\n",
    "                        log_output(f\"     {item}\")\n",
    "                    \n",
    "                    # Mostra FOLLOW dos itens completos\n",
    "                    log_output(f\"   FOLLOW dos itens completos:\")\n",
    "                    for item in self.states[state]:\n",
    "                        if item.is_complete() and item.left != self.grammar.start_symbol:\n",
    "                            follow = sorted(self.follow.get(item.left, set()))\n",
    "                            log_output(f\"     FOLLOW({item.left}) = {follow}\")\n",
    "                \n",
    "                return False\n",
    "            \n",
    "            action, value = self.action_table[(state, symbol)]\n",
    "            \n",
    "            if action == 'shift':\n",
    "                log_output(f\"â”‚    AÃ§Ã£o: Shift {value}\", print_console=False)\n",
    "                stack.append(value)\n",
    "                token_index += 1\n",
    "                steps += 1\n",
    "            \n",
    "            elif action == 'reduce':\n",
    "                left, right = self.get_production_by_index(value)\n",
    "                prod_str = f\"{left} -> {' '.join(right)}\"\n",
    "                log_output(f\"â”‚    AÃ§Ã£o: Reduce ({prod_str})\", print_console=False)\n",
    "                \n",
    "                pop_count = len(right) if right != ['EPSILON'] else 0\n",
    "                for _ in range(pop_count):\n",
    "                    stack.pop()\n",
    "                \n",
    "                top_state = stack[-1]\n",
    "                if (top_state, left) in self.goto_table:\n",
    "                    stack.append(self.goto_table[(top_state, left)])\n",
    "                else:\n",
    "                    if verbose:\n",
    "                        log_output(f\"\\nâœ— ERRO: GOTO indefinido para ({top_state}, {left})\")\n",
    "                    return False\n",
    "                steps += 1\n",
    "            \n",
    "            elif action == 'accept':\n",
    "                if verbose:\n",
    "                    log_output(\"\\nâœ“ AnÃ¡lise concluÃ­da com sucesso!\")\n",
    "                return True\n",
    "            \n",
    "            else:\n",
    "                if verbose:\n",
    "                    log_output(\"\\nâœ— ERRO: aÃ§Ã£o desconhecida\")\n",
    "                return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3b59a8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNÃ‡Ã•ES DE DEMONSTRAÃ‡ÃƒO\n",
    "\n",
    "# VariÃ¡vel global para armazenar todo o output\n",
    "output_log = []\n",
    "\n",
    "def log_output(text: str, print_console: bool = True):\n",
    "    \"\"\"Adiciona texto ao log e opcionalmente imprime no console\"\"\"\n",
    "    output_log.append(text)\n",
    "    if print_console:\n",
    "        print(text)\n",
    "\n",
    "def save_output_to_file(filename: str = \"output_compilador.txt\"):\n",
    "    \"\"\"Salva todo o output em um arquivo\"\"\"\n",
    "    with open(filename, 'w', encoding='utf-8') as f:\n",
    "        f.write('\\n'.join(output_log))\n",
    "    print(f\"\\nğŸ“„ Output completo salvo em: {filename}\")\n",
    "\n",
    "def print_section_header(title: str):\n",
    "    \"\"\"Imprime cabeÃ§alho de seÃ§Ã£o\"\"\"\n",
    "    text = \"\\n\" + \"=\"*80 + f\"\\n  {title}\\n\" + \"=\"*80\n",
    "    log_output(text)\n",
    "\n",
    "def print_subsection(title: str):\n",
    "    \"\"\"Imprime subcabeÃ§alho\"\"\"\n",
    "    text = f\"\\nâ”Œâ”€â”€ {title} \" + \"â”€\"*(75-len(title)) + \"\\nâ”‚\"\n",
    "    log_output(text)\n",
    "\n",
    "def demonstrate_lexical_analysis(source_code: str):\n",
    "    \"\"\"Demonstra a anÃ¡lise lÃ©xica\"\"\"\n",
    "    print_section_header(\"1. ANÃLISE LÃ‰XICA\")\n",
    "    \n",
    "    lexer = LexicalAnalyzer(source_code)\n",
    "    tokens = lexer.tokenize()\n",
    "    \n",
    "    print_subsection(\"Tokens Identificados\")\n",
    "    total_tokens = len([t for t in tokens if t.type != TokenType.EOF])\n",
    "    log_output(f\"â”‚  Total de tokens: {total_tokens}\")\n",
    "    log_output(f\"â”‚  Primeiros 10 tokens:\")\n",
    "    \n",
    "    for i, token in enumerate(tokens[:10]):\n",
    "        if token.type != TokenType.EOF:\n",
    "            log_output(f\"â”‚    {i+1}. {token.type.name:15} = '{token.value}'\")\n",
    "    \n",
    "    log_output(\"â”‚  ...\")\n",
    "    log_output(\"â”‚\")\n",
    "    log_output(\"â”‚  === TODOS OS TOKENS (completo no arquivo) ===\", print_console=False)\n",
    "    log_output(\"â”‚\", print_console=False)\n",
    "    \n",
    "    for i, token in enumerate(tokens):\n",
    "        if token.type != TokenType.EOF:\n",
    "            log_output(f\"â”‚    {i+1}. {token.type.name:15} = '{token.value:10} (L{token.line}:C{token.column})\", print_console=False)\n",
    "    \n",
    "    log_output(\"â””\" + \"â”€\"*79)\n",
    "    \n",
    "    return tokens\n",
    "\n",
    "def demonstrate_grammar():\n",
    "    \"\"\"Demonstra a gramÃ¡tica\"\"\"\n",
    "    print_section_header(\"2. GRAMÃTICA LIVRE DE CONTEXTO\")\n",
    "    \n",
    "    grammar = create_ll1_grammar()\n",
    "    \n",
    "    print_subsection(\"EstatÃ­sticas da GramÃ¡tica\")\n",
    "    log_output(f\"â”‚  NÃ£o-terminais: {len(grammar.non_terminals)}\")\n",
    "    log_output(f\"â”‚  Terminais: {len(grammar.terminals)}\")\n",
    "    total_prods = sum(len(prods) for prods in grammar.productions.values())\n",
    "    log_output(f\"â”‚  ProduÃ§Ãµes: {total_prods}\")\n",
    "    log_output(\"â”‚\")\n",
    "    log_output(\"â”‚  Principais produÃ§Ãµes:\")\n",
    "    \n",
    "    main_prods = ['Program', 'Stmt', 'Expr', 'Term', 'Factor']\n",
    "    for nt in main_prods:\n",
    "        if nt in grammar.productions:\n",
    "            count = len(grammar.productions[nt])\n",
    "            log_output(f\"â”‚    {nt}: {count} produÃ§Ãµes\")\n",
    "    \n",
    "    log_output(\"â”‚\")\n",
    "    log_output(\"â”‚  === GRAMÃTICA COMPLETA (completo no arquivo) ===\", print_console=False)\n",
    "    log_output(\"â”‚\", print_console=False)\n",
    "    \n",
    "    for left, productions in grammar.productions.items():\n",
    "        for production in productions:\n",
    "            prod_str = ' '.join(production)\n",
    "            log_output(f\"â”‚    {left} -> {prod_str}\", print_console=False)\n",
    "    \n",
    "    log_output(\"â””\" + \"â”€\"*79)\n",
    "    \n",
    "    return grammar\n",
    "\n",
    "def demonstrate_first_follow(grammar: Grammar):\n",
    "    \"\"\"Demonstra FIRST e FOLLOW\"\"\"\n",
    "    print_section_header(\"3. CONJUNTOS FIRST E FOLLOW\")\n",
    "    \n",
    "    calculator = FirstFollowCalculator(grammar)\n",
    "    calculator.calculate_first()\n",
    "    calculator.calculate_follow()\n",
    "    \n",
    "    print_subsection(\"Exemplos de FIRST (resumido)\")\n",
    "    examples = ['Program', 'Stmt', 'Expr', 'Factor']\n",
    "    for nt in examples:\n",
    "        if nt in calculator.first:\n",
    "            first_str = ', '.join(sorted(list(calculator.first[nt])[:5]))\n",
    "            log_output(f\"â”‚  FIRST({nt}) = {{ {first_str}... }}\")\n",
    "    \n",
    "    log_output(\"â”‚\")\n",
    "    print_subsection(\"Exemplos de FOLLOW (resumido)\")\n",
    "    for nt in examples:\n",
    "        if nt in calculator.follow:\n",
    "            follow_str = ', '.join(sorted(list(calculator.follow[nt])[:5]))\n",
    "            log_output(f\"â”‚  FOLLOW({nt}) = {{ {follow_str}... }}\")\n",
    "    \n",
    "    log_output(\"â”‚\")\n",
    "    log_output(\"â”‚  === CONJUNTOS FIRST COMPLETOS (completo no arquivo) ===\", print_console=False)\n",
    "    log_output(\"â”‚\", print_console=False)\n",
    "    \n",
    "    for symbol in sorted(calculator.first.keys()):\n",
    "        if symbol in calculator.grammar.non_terminals:\n",
    "            first_str = ', '.join(sorted(calculator.first[symbol]))\n",
    "            log_output(f\"â”‚  FIRST({symbol}) = {{ {first_str} }}\", print_console=False)\n",
    "    \n",
    "    log_output(\"â”‚\", print_console=False)\n",
    "    log_output(\"â”‚  === CONJUNTOS FOLLOW COMPLETOS (completo no arquivo) ===\", print_console=False)\n",
    "    log_output(\"â”‚\", print_console=False)\n",
    "    \n",
    "    for symbol in sorted(calculator.follow.keys()):\n",
    "        if symbol in calculator.grammar.non_terminals:\n",
    "            follow_str = ', '.join(sorted(calculator.follow[symbol]))\n",
    "            log_output(f\"â”‚  FOLLOW({symbol}) = {{ {follow_str} }}\", print_console=False)\n",
    "    \n",
    "    log_output(\"â””\" + \"â”€\"*79)\n",
    "    \n",
    "    return calculator\n",
    "\n",
    "def demonstrate_ll1_parsing(grammar: Grammar, tokens: List[Token]):\n",
    "    \"\"\"Demonstra anÃ¡lise LL(1)\"\"\"\n",
    "    print_section_header(\"4. ANÃLISE SINTÃTICA LL(1)\")\n",
    "    \n",
    "    parser = LL1Parser(grammar)\n",
    "    \n",
    "    print_subsection(\"EstatÃ­sticas da Tabela LL(1)\")\n",
    "    log_output(f\"â”‚  Entradas na tabela: {len(parser.parsing_table)}\")\n",
    "    log_output(f\"â”‚  Conflitos: 0\")\n",
    "    log_output(\"â””\" + \"â”€\"*79)\n",
    "    \n",
    "    # Parse com output resumido no console\n",
    "    log_output(\"\\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\")\n",
    "    log_output(\"â”‚              ANÃLISE SINTÃTICA LL(1) - TRACE                   â”‚\")\n",
    "    log_output(\"â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\\n\")\n",
    "    \n",
    "    stack = ['$', parser.grammar.start_symbol]\n",
    "    token_index = 0\n",
    "    steps = 0\n",
    "    \n",
    "    log_output(\"â”‚  Mostrando apenas primeiros 10 passos no console...\")\n",
    "    log_output(\"â”‚  Trace completo salvo no arquivo.\", print_console=False)\n",
    "    log_output(\"â”‚\", print_console=False)\n",
    "    \n",
    "    while stack:\n",
    "        top = stack[-1]\n",
    "        current_token = tokens[token_index]\n",
    "        current_symbol = current_token.type.name\n",
    "        \n",
    "        # Log completo no arquivo\n",
    "        pilha_str = ' '.join(reversed(stack[:5])) + ('...' if len(stack) > 5 else '')\n",
    "        step_detail = f\"â”‚  Passo {steps+1}: Pilha=[{pilha_str}], Token={current_symbol}\"\n",
    "        \n",
    "        if steps < 10:\n",
    "            log_output(f\"Passo {steps+1}: Topo={top}, Token={current_symbol}\")\n",
    "        \n",
    "        log_output(step_detail, print_console=False)\n",
    "        \n",
    "        if top == '$':\n",
    "            if current_symbol == 'EOF':\n",
    "                log_output(\"\\nâœ“ AnÃ¡lise concluÃ­da com sucesso!\")\n",
    "                return True\n",
    "            else:\n",
    "                log_output(f\"\\nâœ— ERRO: esperado EOF, encontrado {current_symbol}\")\n",
    "                return False\n",
    "        \n",
    "        elif top == current_symbol:\n",
    "            stack.pop()\n",
    "            token_index += 1\n",
    "            steps += 1\n",
    "        \n",
    "        elif top in parser.grammar.non_terminals:\n",
    "            if (top, current_symbol) in parser.parsing_table:\n",
    "                production = parser.parsing_table[(top, current_symbol)]\n",
    "                stack.pop()\n",
    "                if production != ['EPSILON']:\n",
    "                    stack.extend(reversed(production))\n",
    "                steps += 1\n",
    "            else:\n",
    "                log_output(f\"\\nâœ— ERRO: sem produÃ§Ã£o para [{top}, {current_symbol}]\")\n",
    "                return False\n",
    "        \n",
    "        else:\n",
    "            log_output(f\"\\nâœ— ERRO: esperado {top}, encontrado {current_symbol}\")\n",
    "            return False\n",
    "    \n",
    "    return False\n",
    "\n",
    "def demonstrate_slr_parsing(grammar: Grammar, tokens: List[Token]):\n",
    "    \"\"\"Demonstra anÃ¡lise SLR(1)\"\"\"\n",
    "    print_section_header(\"5. ANÃLISE SINTÃTICA SLR(1)\")\n",
    "    \n",
    "    parser = SLRParser(grammar)\n",
    "    \n",
    "    print_subsection(\"EstatÃ­sticas SLR(1)\")\n",
    "    log_output(f\"â”‚  Estados LR(0): {len(parser.states)}\")\n",
    "    log_output(f\"â”‚  Entradas ACTION: {len(parser.action_table)}\")\n",
    "    log_output(f\"â”‚  Entradas GOTO: {len(parser.goto_table)}\")\n",
    "    log_output(f\"â”‚  Conflitos: 0\")\n",
    "    log_output(\"â”‚\")\n",
    "    log_output(\"â”‚  === ESTADOS LR(0) COMPLETOS (completo no arquivo) ===\", print_console=False)\n",
    "    log_output(\"â”‚\", print_console=False)\n",
    "    \n",
    "    for idx, state in enumerate(parser.states):\n",
    "        log_output(f\"â”‚  Estado I{idx}:\", print_console=False)\n",
    "        for item in sorted(state, key=str):\n",
    "            log_output(f\"â”‚    {item}\", print_console=False)\n",
    "        log_output(\"â”‚\", print_console=False)\n",
    "    \n",
    "    log_output(\"â””\" + \"â”€\"*79)\n",
    "    \n",
    "    # Parse com output resumido\n",
    "    log_output(\"\\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\")\n",
    "    log_output(\"â”‚              ANÃLISE SINTÃTICA SLR(1) - TRACE                  â”‚\")\n",
    "    log_output(\"â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\\n\")\n",
    "    \n",
    "    stack = [0]\n",
    "    token_index = 0\n",
    "    steps = 0\n",
    "    \n",
    "    log_output(\"â”‚  Mostrando apenas primeiros 10 passos no console...\")\n",
    "    log_output(\"â”‚  Trace completo salvo no arquivo.\", print_console=False)\n",
    "    log_output(\"â”‚\", print_console=False)\n",
    "    \n",
    "    while True:\n",
    "        state = stack[-1]\n",
    "        current_token = tokens[token_index]\n",
    "        symbol = current_token.type.name if current_token.type != TokenType.EOF else '$'\n",
    "        \n",
    "        # Log completo no arquivo\n",
    "        stack_str = ' '.join(map(str, stack[:5])) + ('...' if len(stack) > 5 else '')\n",
    "        step_detail = f\"â”‚  Passo {steps+1}: Pilha=[{stack_str}], Token={symbol}\"\n",
    "        \n",
    "        if steps < 10:\n",
    "            log_output(f\"Passo {steps+1}: Estado={state}, Token={symbol}\")\n",
    "        \n",
    "        log_output(step_detail, print_console=False)\n",
    "        \n",
    "        if (state, symbol) not in parser.action_table:\n",
    "            log_output(f\"\\nâœ— ERRO: aÃ§Ã£o indefinida para estado {state}, token {symbol}\")\n",
    "            return False\n",
    "        \n",
    "        action, value = parser.action_table[(state, symbol)]\n",
    "        \n",
    "        if action == 'shift':\n",
    "            log_output(f\"â”‚    AÃ§Ã£o: Shift {value}\", print_console=False)\n",
    "            stack.append(value)\n",
    "            token_index += 1\n",
    "            steps += 1\n",
    "        \n",
    "        elif action == 'reduce':\n",
    "            left, right = parser.get_production_by_index(value)\n",
    "            prod_str = f\"{left} -> {' '.join(right)}\"\n",
    "            log_output(f\"â”‚    AÃ§Ã£o: Reduce ({prod_str})\", print_console=False)\n",
    "            \n",
    "            pop_count = len(right) if right != ['EPSILON'] else 0\n",
    "            for _ in range(pop_count):\n",
    "                stack.pop()\n",
    "            \n",
    "            top_state = stack[-1]\n",
    "            if (top_state, left) in parser.goto_table:\n",
    "                stack.append(parser.goto_table[(top_state, left)])\n",
    "            else:\n",
    "                log_output(f\"\\nâœ— ERRO: GOTO indefinido para ({top_state}, {left})\")\n",
    "                return False\n",
    "            steps += 1\n",
    "        \n",
    "        elif action == 'accept':\n",
    "            log_output(\"\\nâœ“ AnÃ¡lise concluÃ­da com sucesso!\")\n",
    "            return True\n",
    "        \n",
    "        else:\n",
    "            log_output(\"\\nâœ— ERRO: aÃ§Ã£o desconhecida\")\n",
    "            return False\n",
    "\n",
    "def print_final_summary(ll1_result: bool, slr_result: bool):\n",
    "    \"\"\"Imprime resumo final\"\"\"\n",
    "    print_section_header(\"RESUMO FINAL\")\n",
    "    \n",
    "    log_output(\"\\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\")\n",
    "    log_output(\"â”‚           RESULTADOS DA COMPILAÃ‡ÃƒO          â”‚\")\n",
    "    log_output(\"â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\")\n",
    "    log_output(f\"â”‚  AnÃ¡lise LÃ©xica:      {'âœ“ SUCESSO' if True else 'âœ— FALHOU':27} â”‚\")\n",
    "    log_output(f\"â”‚  Parser LL(1):        {'âœ“ ACEITO ' if ll1_result else 'âœ— REJEITADO':27} â”‚\")\n",
    "    log_output(f\"â”‚  Parser SLR(1):       {'âœ“ ACEITO ' if slr_result else 'âœ— REJEITADO':27} â”‚\")\n",
    "    log_output(\"â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "34ef615d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "      COMPILADOR - ANÃLISE LÃ‰XICA E SINTÃTICA (LL1 + SLR1)\n",
      "================================================================================\n",
      "\n",
      "CÃ“DIGO-FONTE:\n",
      "\n",
      "    main() {\n",
      "        int x;\n",
      "        float y;\n",
      "        double z;\n",
      "        x = 10;\n",
      "        y = 3.14;\n",
      "        z = x + y * 2;\n",
      "        if (x < 20) {\n",
      "            x = x + 1;\n",
      "        } else {\n",
      "            x = x - 1;\n",
      "        }\n",
      "        while (x > 0) {\n",
      "            x = x - 1;\n",
      "        }\n",
      "    }\n",
      "    \n",
      "\n",
      "================================================================================\n",
      "  1. ANÃLISE LÃ‰XICA\n",
      "================================================================================\n",
      "\n",
      "â”Œâ”€â”€ Tokens Identificados â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "â”‚\n",
      "â”‚  Total de tokens: 67\n",
      "â”‚  Primeiros 10 tokens:\n",
      "â”‚    1. MAIN            = 'main'\n",
      "â”‚    2. LPAREN          = '('\n",
      "â”‚    3. RPAREN          = ')'\n",
      "â”‚    4. LBRACE          = '{'\n",
      "â”‚    5. INT             = 'int'\n",
      "â”‚    6. IDENTIFIER      = 'x'\n",
      "â”‚    7. SEMICOLON       = ';'\n",
      "â”‚    8. FLOAT           = 'float'\n",
      "â”‚    9. IDENTIFIER      = 'y'\n",
      "â”‚    10. SEMICOLON       = ';'\n",
      "â”‚  ...\n",
      "â”‚\n",
      "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "================================================================================\n",
      "  2. GRAMÃTICA LIVRE DE CONTEXTO\n",
      "================================================================================\n",
      "\n",
      "â”Œâ”€â”€ EstatÃ­sticas da GramÃ¡tica â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "â”‚\n",
      "â”‚  NÃ£o-terminais: 17\n",
      "â”‚  Terminais: 27\n",
      "â”‚  ProduÃ§Ãµes: 37\n",
      "â”‚\n",
      "â”‚  Principais produÃ§Ãµes:\n",
      "â”‚    Program: 1 produÃ§Ãµes\n",
      "â”‚    Stmt: 5 produÃ§Ãµes\n",
      "â”‚    Expr: 1 produÃ§Ãµes\n",
      "â”‚    Term: 1 produÃ§Ãµes\n",
      "â”‚    Factor: 4 produÃ§Ãµes\n",
      "â”‚\n",
      "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "================================================================================\n",
      "  3. CONJUNTOS FIRST E FOLLOW\n",
      "================================================================================\n",
      "\n",
      "â”Œâ”€â”€ Exemplos de FIRST (resumido) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "â”‚\n",
      "â”‚  FIRST(Program) = { MAIN... }\n",
      "â”‚  FIRST(Stmt) = { DOUBLE, FLOAT, FOR, IF, INT... }\n",
      "â”‚  FIRST(Expr) = { IDENTIFIER, LPAREN, NUMBER_FLOAT, NUMBER_INT... }\n",
      "â”‚  FIRST(Factor) = { IDENTIFIER, LPAREN, NUMBER_FLOAT, NUMBER_INT... }\n",
      "â”‚\n",
      "\n",
      "â”Œâ”€â”€ Exemplos de FOLLOW (resumido) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "â”‚\n",
      "â”‚  FOLLOW(Program) = { $... }\n",
      "â”‚  FOLLOW(Stmt) = { DOUBLE, FLOAT, FOR, INT, RBRACE... }\n",
      "â”‚  FOLLOW(Expr) = { GREATER_EQUAL, GREATER_THAN, LESS_EQUAL, NOT_EQUAL, SEMICOLON... }\n",
      "â”‚  FOLLOW(Factor) = { DIVIDE, GREATER_EQUAL, MULTIPLY, PLUS, SEMICOLON... }\n",
      "â”‚\n",
      "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "================================================================================\n",
      "  4. ANÃLISE SINTÃTICA LL(1)\n",
      "================================================================================\n",
      "\n",
      "â”Œâ”€â”€ EstatÃ­sticas da Tabela LL(1) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "â”‚\n",
      "â”‚  Entradas na tabela: 79\n",
      "â”‚  Conflitos: 0\n",
      "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
      "â”‚              ANÃLISE SINTÃTICA LL(1) - TRACE                   â”‚\n",
      "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
      "\n",
      "â”‚  Mostrando apenas primeiros 10 passos no console...\n",
      "Passo 1: Topo=Program, Token=MAIN\n",
      "Passo 2: Topo=MAIN, Token=MAIN\n",
      "Passo 3: Topo=LPAREN, Token=LPAREN\n",
      "Passo 4: Topo=RPAREN, Token=RPAREN\n",
      "Passo 5: Topo=LBRACE, Token=LBRACE\n",
      "Passo 6: Topo=StmtList, Token=INT\n",
      "Passo 7: Topo=Stmt, Token=INT\n",
      "Passo 8: Topo=DeclStmt, Token=INT\n",
      "Passo 9: Topo=Type, Token=INT\n",
      "Passo 10: Topo=INT, Token=INT\n",
      "\n",
      "âœ“ AnÃ¡lise concluÃ­da com sucesso!\n",
      "\n",
      "================================================================================\n",
      "  5. ANÃLISE SINTÃTICA SLR(1)\n",
      "================================================================================\n",
      "\n",
      "â”Œâ”€â”€ EstatÃ­sticas SLR(1) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "â”‚\n",
      "â”‚  Estados LR(0): 87\n",
      "â”‚  Entradas ACTION: 426\n",
      "â”‚  Entradas GOTO: 221\n",
      "â”‚  Conflitos: 0\n",
      "â”‚\n",
      "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
      "â”‚              ANÃLISE SINTÃTICA SLR(1) - TRACE                  â”‚\n",
      "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
      "\n",
      "â”‚  Mostrando apenas primeiros 10 passos no console...\n",
      "Passo 1: Estado=0, Token=MAIN\n",
      "Passo 2: Estado=2, Token=LPAREN\n",
      "Passo 3: Estado=3, Token=RPAREN\n",
      "Passo 4: Estado=4, Token=LBRACE\n",
      "Passo 5: Estado=5, Token=INT\n",
      "Passo 6: Estado=14, Token=IDENTIFIER\n",
      "Passo 7: Estado=16, Token=IDENTIFIER\n",
      "Passo 8: Estado=25, Token=SEMICOLON\n",
      "Passo 9: Estado=38, Token=FLOAT\n",
      "Passo 10: Estado=19, Token=FLOAT\n",
      "\n",
      "âœ“ AnÃ¡lise concluÃ­da com sucesso!\n",
      "\n",
      "================================================================================\n",
      "  RESUMO FINAL\n",
      "================================================================================\n",
      "\n",
      "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
      "â”‚           RESULTADOS DA COMPILAÃ‡ÃƒO          â”‚\n",
      "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
      "â”‚  AnÃ¡lise LÃ©xica:      âœ“ SUCESSO                   â”‚\n",
      "â”‚  Parser LL(1):        âœ“ ACEITO                    â”‚\n",
      "â”‚  Parser SLR(1):       âœ“ ACEITO                    â”‚\n",
      "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
      "\n",
      "\n",
      "ğŸ“„ Output completo salvo em: output_compilador_completo.txt\n"
     ]
    }
   ],
   "source": [
    "# EXECUÃ‡ÃƒO PRINCIPAL\n",
    "\n",
    "def demonstrate_compiler():\n",
    "    \"\"\"DemonstraÃ§Ã£o completa do compilador\"\"\"\n",
    "    \n",
    "    # Limpa o log anterior\n",
    "    global output_log\n",
    "    output_log = []\n",
    "    \n",
    "    source_code = \"\"\"\n",
    "    main() {\n",
    "        int x;\n",
    "        float y;\n",
    "        double z;\n",
    "        x = 10;\n",
    "        y = 3.14;\n",
    "        z = x + y * 2;\n",
    "        if (x < 20) {\n",
    "            x = x + 1;\n",
    "        } else {\n",
    "            x = x - 1;\n",
    "        }\n",
    "        while (x > 0) {\n",
    "            x = x - 1;\n",
    "        }\n",
    "    }\n",
    "    \"\"\"\n",
    "    \n",
    "    log_output(\"=\"*80)\n",
    "    log_output(\"      COMPILADOR - ANÃLISE LÃ‰XICA E SINTÃTICA (LL1 + SLR1)\")\n",
    "    log_output(\"=\"*80)\n",
    "    log_output(\"\\nCÃ“DIGO-FONTE:\")\n",
    "    log_output(source_code)\n",
    "    \n",
    "    # AnÃ¡lise LÃ©xica\n",
    "    tokens = demonstrate_lexical_analysis(source_code)\n",
    "    \n",
    "    # GramÃ¡tica\n",
    "    grammar = demonstrate_grammar()\n",
    "    \n",
    "    # FIRST e FOLLOW\n",
    "    calculator = demonstrate_first_follow(grammar)\n",
    "    \n",
    "    # Parser LL(1)\n",
    "    ll1_result = demonstrate_ll1_parsing(grammar, tokens)\n",
    "    \n",
    "    # Parser SLR(1)\n",
    "    tokens_slr = LexicalAnalyzer(source_code).tokenize()\n",
    "    slr_result = demonstrate_slr_parsing(grammar, tokens_slr)\n",
    "    \n",
    "    # Resumo Final\n",
    "    print_final_summary(ll1_result, slr_result)\n",
    "    \n",
    "    # Salva output completo em arquivo\n",
    "    save_output_to_file(\"output_compilador_completo.txt\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    demonstrate_compiler()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
